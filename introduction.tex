\section{Background}\label{sec:notation}
The central focus of this work is an instance of an LLM, denoted $\mathcal{M}$. 
When appropriate, we can differentiate between instances with a lower index, specifying its purpose. 
For example, when using separate LLM instances for optimizing and task-solving, we will denote them $\mathcal{M}_{optim}$ and $\mathcal{M}_{solve}$ respectively.
This way, we put emphasis on the fact we can choose a different LLM provider and hyperparameters for each instance.


In general, $\mathcal{M}: \mathbb{T} \times \mathbb{T}$ is a stochastic (for a positive sampling temperature) mapping on the space of text sequences $\mathbb{T}$.
A prompt $P \in \mathbb{T}$ is a text sequence that, when inputted into an LLM, produces an output
\begin{equation}
    y \sim \mathcal{M}(P).
\end{equation} 

We can use LLMs to solve a general task
\begin{equation}
    t \in \mathcal{D} \vsep \mathcal{D} = \{ (q_1, g_1), (q_2, g_2), ... , (q_n, g_n), \},
\end{equation}
where $\mathbb{D}$ is a dataset consisting of $n$ pairs of queries $q$ and gold-labels $g$. 
For open-ended tasks, the gold-label does not exist, $g_k = \varnothing \forall k$.


We can further define a prompt as
\begin{equation}
    P = \mathbf{p}(q),
\end{equation}
where $\mathbf{p} \in \mathbf{T}$ is a set of text instructions into which a task query $q$ is inserted. 
We will call the text instructions $p$ a \textit{prompt template}.

\begin{algorithm}
    \caption{General optimization loop}
    \label{alg:genoptimloop}
    \KwIn{Initialization Operator $\mathcal{O}_I$, Selection Operator $\mathcal{O}_S$, Expansion Operator $\mathcal{O}_E$, Termination Condition $\Phi_{stop}$}
    \KwOut{Optimized Population $\mathcal{P}$}
    \KwData{$\mathcal{P} \gets \mathcal{O}_I$} \tcp{Initialize the population}
    \While{$\neg \Phi_{stop}(\mathcal{P})$}{
        \tcp{Selection and Expansion Steps}
        $\mathcal{P}_{\text{selected}} \gets \mathcal{O}_S(\mathcal{P})$ \\ 
        $\mathcal{P}_{\text{expanded}} \gets \mathcal{O}_E(\mathcal{P}_{\text{selected}})$ \\
        $\mathcal{P} \gets \mathcal{P}_{\text{expanded}}$ \tcp{Update the population} 
        }
        \Return{$\mathcal{P}$} \tcp{Return the optimized population}
    \end{algorithm}
    
Next, we move onto the optimization notation. In Algorithm \ref{alg:genoptimloop} we can see the general outline of a population-based optimization method.
The initialization operator $\mathcal{O}_I$ creates an initial population of individuals $\mathcal{P}$. 
Then, in each step, a selection operator $\mathcal{O}_S$ selects a portion of the population according to some criteria. 
These selected individuals are then used by the expansion operator $\mathcal{O}_E$ to create new individuals.
This process continues until a termination condition $\Phi_{stop}$ is reached.